[
{
	"uri": "/r_content/btc/btc_02/btc_02.html",
	"title": "A Bit of Style",
	"tags": [],
	"description": "",
	"content": "2021-03-11, FCA Collin\nStyle Advises Use Comment Appropriately Main reason to comment:\n Code Readability Explanation of the code or Metadata of the project Temporarily prevent execution of code To include resources  https://style.tidyverse.org/syntax.html (210415):\nIn data analysis code, use comments to record important findings and analysis decisions. If you need comments to explain what your code is doing, consider rewriting your code to be clearer. If you discover that you have more comments than code, consider switching to R Markdown.\nHow to comment https://style.tidyverse.org/functions.html (210415):\n Explain the why and not the what or how Comments should be in sentence case, and only end with a full stop if they contain at least two sentences  Down-side of (bad) comment practice.  Focus and cognitive load: stops screening code because maybe that is important (and 99% of case is not). Hides what’s important: increase the length of the code. If, eventually, it is understood by the programmer who commented it, it is noise to every one else. It is better to keep the code to the necessary piece and as, along with other measures, it will improve code maintenance by preventing to have to look for the needle in the haystack.  Alternative: if all this comment is necessary, use literate programming such as rmarkdown.  The commented code does not evolve and may become out of date: and this is a problem as all the code should work. Unfinished job: the comment can be an alternative code as the programmer thinks “*maybe that could be another valid approach*”. The programmer is still the better placed to decided what is better, or may ask advises, but the job will be finish when finally ruling the decision. Alternative:  if it is hard to decide, take the time to weight the decision, eventually ask another colleague. if the decision must be documented: consider literate programming with rmarkdown.  Someone else will delete it. As ambiguous, someone may decide to delete the commented code. If this was really informative, that will be a loss which could have been prevented (i.e. literate programming, unit tests). Some programmers think:  I’ll Delete Your Commented Code Without Reading It and I’m Not Sorry https://blog.submain.com/delete-commented-code-without-reading/   Around the Web:\n https://kentcdodds.com/blog/please-dont-commit-commented-out-code https://agiletribe.wordpress.com/2015/12/26/never-leave-commented-code-in-the-source/ https://blog.submain.com/delete-commented-code-without-reading/  Few quotes:\n The cost of that commented code always outweighs the benefit. Deleting commented code is an easy and effective way to improve the code base, without any risk of negative consequences.  sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.4 magrittr_2.0.1 tools_4.0.4 htmltools_0.5.1.1 ## [5] yaml_2.2.1 stringi_1.5.3 rmarkdown_2.6 knitr_1.31 ## [9] stringr_1.4.0 xfun_0.22 digest_0.6.27 rlang_0.4.10 ## [13] evaluate_0.14 "
},
{
	"uri": "/r_content/btc/btc_01/btc_01.html",
	"title": "Beat The Code",
	"tags": [],
	"description": "",
	"content": "2021-03-11, FCA Collin\nTidyverse, Not a Golden Hammer The Law of the instrument describes a cognitive bias:\n “I call it the law of the instrument, and it may be formulated as follows: Give a small boy a hammer, and he will find that everything he encounters needs pounding.” (Abraham Kaplan, 1964)\n It was identified as an AntiPattern, a programming practice to be avoided (William Brown et al, 1998). One of the pit fall is expressed as:\n “the tendency of jobs to be adapted to tools, rather than adapting tools to jobs” (Silvan Tomkins, 1963).\n The tidyverse package helps end-user in R-coding delimited statistic tasks. It is a very good idea to use it if your purpose is to walk through an analysis from a point A (the dataset) to the point B (the result) for procedures of limited complexity. Indeed, with a limited number of human-readable functions you can get the expected result while helping the future reader to follow the procedure. However, as soon as you want to resolve statistical problems in a more systemic way, by creating functions that will help you to get your result in a more concise (because accurate) code and tested for and documented and robust, tidyverse is not the most suitable choice.\nThe package vignette itself enclose a clear disclaimer about the package rational:\n “the biggest difference is in priorities: base R is highly focussed on stability, whereas the tidyverse will make breaking changes in the search for better interfaces.” Welcome to the Tidyverse vignette, 2019\n The trade-off between stability and interface evolution is also acknowledged:\n Do you expect the tidyverse to be the part of core R packages some day?\nHadley Wickham: “It’s extremely unlikely because the core packages are extremely conservative so that base R code is stable, and backward compatible. I prefer to have a more utopian approach where I can be quite aggressive about making backward incompatible changes while trying to figure out a better API.” quora\n There is no doubt that tidyverse is a set of high quality tools, but it is designed to serve some purpose: easy and highly readable code at the cost of stability which is a strategy which can’t serve all developments. Besides, the over reliance of craftsperson on a known tool, brings to see the challenge not as it is but how it fit to the tool. As a matter of fact, an over reliance on tidyverse risk to introduce a cognitive bias, increasing the risk of of deviation from initial target as fitting your purpose to the problem instead of making the method suitable to answer specific question. The over-reliance can be evidence by a large tidyverse block which have obviously lost the main sells argument of the package: readability.\nIn order to increase the range of possible ways to address a question, so as to minimise the risk of programming cognitive bias, it is good to demonstrate alternatives to the tidyverse approach put in some context, and present the R base alternative. There will be a trade-off switching from one to the other about readability, performance and code stability. But, maybe, this will also help thinking about different approaches to address statistical problems.\nFilter and Select library(tidyverse) Tidyerse Non-Standard Evaluation:\niris %\u0026gt;% filter(Species == \u0026#34;setosa\u0026#34;) %\u0026gt;% select(Sepal.Width, Sepal.Length) %\u0026gt;% head ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base Non-Standard Evaluation:\nsel \u0026lt;- subset( iris, subset = Species == \u0026#34;setosa\u0026#34;, select = c(Sepal.Width, Sepal.Length) ) head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base data.frame accessors:\nsel \u0026lt;- iris[ iris$Species == \u0026#34;setosa\u0026#34;, c(\u0026#34;Sepal.Width\u0026#34;, \u0026#34;Sepal.Length\u0026#34;) ] head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Mutate df[df$age \u0026gt; 90, ] \u0026lt;- NAsessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.5 purrr_0.3.4 ## [5] readr_1.4.0 tidyr_1.1.3 tibble_3.1.0 ggplot2_3.3.3 ## [9] tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.0 xfun_0.22 haven_2.3.1 colorspace_2.0-0 ## [5] vctrs_0.3.7 generics_0.1.0 htmltools_0.5.1.1 yaml_2.2.1 ## [9] utf8_1.2.1 rlang_0.4.10 pillar_1.5.1 withr_2.4.1 ## [13] glue_1.4.2 DBI_1.1.1 dbplyr_2.0.0 modelr_0.1.8 ## [17] readxl_1.3.1 lifecycle_1.0.0 munsell_0.5.0 gtable_0.3.0 ## [21] cellranger_1.1.0 rvest_1.0.0 evaluate_0.14 knitr_1.31 ## [25] ps_1.6.0 fansi_0.4.2 broom_0.7.5 Rcpp_1.0.6 ## [29] scales_1.1.1 backports_1.2.1 jsonlite_1.7.2 fs_1.5.0 ## [33] hms_1.0.0 digest_0.6.27 stringi_1.5.3 grid_4.0.4 ## [37] cli_2.3.1 tools_4.0.4 magrittr_2.0.1 crayon_1.4.1 ## [41] pkgconfig_2.0.3 ellipsis_0.3.1 xml2_1.3.2 reprex_1.0.0 ## [45] lubridate_1.7.10 assertthat_0.2.1 rmarkdown_2.6 httr_1.4.2 ## [49] rstudioapi_0.13 R6_2.5.0 compiler_4.0.4 "
},
{
	"uri": "/r_content/utils_01/btc_01.html",
	"title": "Beat The Code",
	"tags": [],
	"description": "",
	"content": "2021-03-11, FCA Collin\nTidyverse, Not a Golden Hammer The Law of the instrument describes a cognitive bias:\n “I call it the law of the instrument, and it may be formulated as follows: Give a small boy a hammer, and he will find that everything he encounters needs pounding.” (Abraham Kaplan, 1964)\n It was identified as an AntiPattern, a programming practice to be avoided (William Brown et al, 1998). One of the pit fall is expressed as:\n “the tendency of jobs to be adapted to tools, rather than adapting tools to jobs” (Silvan Tomkins, 1963).\n The tidyverse package helps end-user in R-coding delimited statistic tasks. It is a very good idea to use it if your purpose is to walk through an analysis from a point A (the dataset) to the point B (the result) for procedures of limited complexity. Indeed, with a limited number of human-readable functions you can get the expected result while helping the future reader to follow the procedure. However, as soon as you want to resolve statistical problems in a more systemic way, by creating functions that will help you to get your result in a more concise (because accurate) code and tested for and documented and robust, tidyverse is not the most suitable choice.\nThe package vignette itself enclose a clear disclaimer about the package rational:\n “the biggest difference is in priorities: base R is highly focussed on stability, whereas the tidyverse will make breaking changes in the search for better interfaces.” Welcome to the Tidyverse vignette, 2019\n The trade-off between stability and interface evolution is also acknowledged:\n Do you expect the tidyverse to be the part of core R packages some day?\nHadley Wickham: “It’s extremely unlikely because the core packages are extremely conservative so that base R code is stable, and backward compatible. I prefer to have a more utopian approach where I can be quite aggressive about making backward incompatible changes while trying to figure out a better API.” quora\n There is no doubt that tidyverse is a set of high quality tools, but it is designed to serve some purpose: easy and highly readable code at the cost of stability which is a strategy which can’t serve all developments. Besides, the over reliance of craftsperson on a known tool, brings to see the challenge not as it is but how it fit to the tool. As a matter of fact, an over reliance on tidyverse risk to introduce a cognitive bias, increasing the risk of of deviation from initial target as fitting your purpose to the problem instead of making the method suitable to answer specific question. The over-reliance can be evidence by a large tidyverse block which have obviously lost the main sells argument of the package: readability.\nIn order to increase the range of possible ways to address a question, so as to minimise the risk of programming cognitive bias, it is good to demonstrate alternatives to the tidyverse approach put in some context, and present the R base alternative. There will be a trade-off switching from one to the other about readability, performance and code stability. But, maybe, this will also help thinking about different approaches to address statistical problems.\nFilter and Select library(tidyverse)  Tidyerse Non-Standard Evaluation:\niris %\u0026gt;% filter(Species == \u0026quot;setosa\u0026quot;) %\u0026gt;% select(Sepal.Width, Sepal.Length) %\u0026gt;% head ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base Non-Standard Evaluation:\nsel \u0026lt;- subset( iris, subset = Species == \u0026quot;setosa\u0026quot;, select = c(Sepal.Width, Sepal.Length) ) head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base data.frame accessors:\nsel \u0026lt;- iris[ iris$Species == \u0026quot;setosa\u0026quot;, c(\u0026quot;Sepal.Width\u0026quot;, \u0026quot;Sepal.Length\u0026quot;) ] head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Mutate df[df$age \u0026gt; 90, ] \u0026lt;- NA sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.5 purrr_0.3.4 ## [5] readr_1.4.0 tidyr_1.1.3 tibble_3.1.0 ggplot2_3.3.3 ## [9] tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.0 xfun_0.22 haven_2.3.1 colorspace_2.0-0 ## [5] vctrs_0.3.6 generics_0.1.0 htmltools_0.5.1.1 yaml_2.2.1 ## [9] utf8_1.2.1 rlang_0.4.10 pillar_1.5.1 withr_2.4.1 ## [13] glue_1.4.2 DBI_1.1.1 dbplyr_2.0.0 modelr_0.1.8 ## [17] readxl_1.3.1 lifecycle_1.0.0 munsell_0.5.0 gtable_0.3.0 ## [21] cellranger_1.1.0 rvest_1.0.0 evaluate_0.14 knitr_1.31 ## [25] ps_1.6.0 fansi_0.4.2 broom_0.7.5 Rcpp_1.0.6 ## [29] scales_1.1.1 backports_1.2.1 jsonlite_1.7.2 fs_1.5.0 ## [33] hms_1.0.0 digest_0.6.27 stringi_1.5.3 grid_4.0.4 ## [37] cli_2.3.1 tools_4.0.4 magrittr_2.0.1 crayon_1.4.1 ## [41] pkgconfig_2.0.3 ellipsis_0.3.1 xml2_1.3.2 reprex_1.0.0 ## [45] lubridate_1.7.10 assertthat_0.2.1 rmarkdown_2.6 httr_1.4.2 ## [49] rstudioapi_0.13 R6_2.5.0 compiler_4.0.4 "
},
{
	"uri": "/r_content/utils_01/utils_01.html",
	"title": "Utils",
	"tags": [],
	"description": "",
	"content": "2021-03-19, FCA Collin\nDummy var #\u0026#39; Dummy Variable #\u0026#39; #\u0026#39; Decompose a factor-coercible variable into dummy variables. #\u0026#39;  #\u0026#39; @param x (`atomic`) #\u0026#39; @export #\u0026#39; @source \u0026lt;https://fcacollin.github.io/guide/utils_01/utils_01.html\u0026gt; #\u0026#39; @md #\u0026#39; @examples #\u0026#39; # Use case data.frame. #\u0026#39; head(iris) #\u0026#39; head(dummy_var(iris$Species)) #\u0026#39; iris$sp \u0026lt;- dummy_var(iris$Species) #\u0026#39; head(iris) #\u0026#39;  #\u0026#39; # With logical. #\u0026#39; dummy_var(c(TRUE, FALSE)) #\u0026#39;  #\u0026#39; # With character. #\u0026#39; dummy_var(c(\u0026#34;cat\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34;, \u0026#34;corgi\u0026#34;, \u0026#34;corgi\u0026#34;)) #\u0026#39;  dummy_var \u0026lt;- function(x) { stopifnot(is.atomic(x)) if (!is.factor(x)) { x \u0026lt;- as.factor(x) } x \u0026lt;- droplevels(x) y \u0026lt;- stats::model.matrix(~ x + 0) colnames(y) \u0026lt;- levels(x) as.data.frame(y) }# Use case data.frame. head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa  head(dummy_var(iris$Species)) ## setosa versicolor virginica ## 1 1 0 0 ## 2 1 0 0 ## 3 1 0 0 ## 4 1 0 0 ## 5 1 0 0 ## 6 1 0 0  iris$sp \u0026lt;- dummy_var(iris$Species) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species sp.setosa ## 1 5.1 3.5 1.4 0.2 setosa 1 ## 2 4.9 3.0 1.4 0.2 setosa 1 ## 3 4.7 3.2 1.3 0.2 setosa 1 ## 4 4.6 3.1 1.5 0.2 setosa 1 ## 5 5.0 3.6 1.4 0.2 setosa 1 ## 6 5.4 3.9 1.7 0.4 setosa 1 ## sp.versicolor sp.virginica ## 1 0 0 ## 2 0 0 ## 3 0 0 ## 4 0 0 ## 5 0 0 ## 6 0 0  # With logical. dummy_var(c(TRUE, FALSE)) ## FALSE TRUE ## 1 0 1 ## 2 1 0  # With character. dummy_var(c(\u0026#34;cat\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34;, \u0026#34;corgi\u0026#34;, \u0026#34;corgi\u0026#34;)) ## cat corgi dog ## 1 1 0 0 ## 2 1 0 0 ## 3 0 0 1 ## 4 0 1 0 ## 5 0 1 0  Matrix To Long Format #\u0026#39; Matrix-like Data To Long Data Frame #\u0026#39; #\u0026#39; Transform a matrix-like data set into a long data frame. #\u0026#39; mat_to_long_df \u0026lt;- function(x, ...) { UseMethod(\u0026#34;mat_to_long_df\u0026#34;, x) } mat_to_long_df.matrix \u0026lt;- function(x, names = c(\u0026#34;row\u0026#34;, \u0026#34;col\u0026#34;, \u0026#34;value\u0026#34;), ...) { assertthat::assert_that(length(names) == 3L) if (is.null(colnames(x))) colnames(x) \u0026lt;- as.character(seq_len(ncol(x))) if (is.null(rownames(x))) rownames(x) \u0026lt;- as.character(seq_len(nrow(x))) y \u0026lt;- data.frame( rownames(x)[c(row(x))], colnames(x)[c(col(x))], c(x), row.names = NULL ) names(y) \u0026lt;- names y } mat_to_long_df.data.frame \u0026lt;- function(x, ...) { x \u0026lt;- as.matrix(x) mat_to_long_df(x, ...) } m \u0026lt;- matrix( c( 11, 12, 21, 22, 31, 32 ), nrow = 3, byrow = TRUE, dimnames = list(row = 1:3, col = 1:2) ) df \u0026lt;- as.data.frame(m) mat_to_long_df(m) ## row col value ## 1 1 1 11 ## 2 2 1 21 ## 3 3 1 31 ## 4 1 2 12 ## 5 2 2 22 ## 6 3 2 32  mat_to_long_df(df) ## row col value ## 1 1 1 11 ## 2 2 1 21 ## 3 3 1 31 ## 4 1 2 12 ## 5 2 2 22 ## 6 3 2 32  library(testthat) test_that(\u0026#34;mat_to_long_df names are used\u0026#34;, { result \u0026lt;- mat_to_long_df(m, names = c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;y\u0026#34;)) expected \u0026lt;- data.frame( a = c(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;), b = c(\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;2\u0026#34;), y = c(11, 21, 31, 12, 22, 32) ) expect_identical(result, expected) }) ## Test passed 🌈  test_that(\u0026#34;mat_to_long_df error if not 3 names provided\u0026#34;, { expect_error(mat_to_long_df(m, names = \u0026#34;a\u0026#34;)) }) ## Test passed 🥇  sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] testthat_3.0.2 ## ## loaded via a namespace (and not attached): ## [1] ps_1.6.0 rprojroot_2.0.2 crayon_1.4.1 digest_0.6.27 ## [5] withr_2.4.1 assertthat_0.2.1 R6_2.5.0 magrittr_2.0.1 ## [9] evaluate_0.14 cli_2.5.0 rlang_0.4.11 stringi_1.5.3 ## [13] rstudioapi_0.13 rmarkdown_2.6 desc_1.3.0 tools_4.0.4 ## [17] stringr_1.4.0 xfun_0.22 pkgload_1.1.0 yaml_2.2.1 ## [21] compiler_4.0.4 htmltools_0.5.1.1 knitr_1.33 "
},
{
	"uri": "/standard/lifecycle/lcycle_01.html",
	"title": "Lifecycle",
	"tags": ["lifecycle"],
	"description": "",
	"content": "2021-03-09, FCA Collin\nPresentation of lifecycle status and shields used in production\nDocument Edition In Edit The Doc/In Edit shield indicates a section or document being currently edited. For the sake of comunication with the stakeholder, the document (or section within the document) may nonetheless have been released in spite of not having reach stability. This section/document is:\n unstable, likely to evolve. not validated: use the information within this section at your own risk. open for general overview and major comments. closed to minor comments. "
},
{
	"uri": "/faq/git/git_01.html",
	"title": "Git Help",
	"tags": ["error", "warning", "debug"],
	"description": "",
	"content": "2021-03-08, FCA Collin\nCommon Problems With Git I have forgotten to start a feature branch and started modifying the devel git stash git checkout -b feat_branch git stash pop "
},
{
	"uri": "/faq/r_package/errors_01.html",
	"title": "R Pack Debug",
	"tags": ["error", "warning", "debug"],
	"description": "",
	"content": "2021-03-05, FCA Collin\nErrors and Warnings with R @export may only span a single line  Context: documenting a package with devtools::document() (ctrl+shift+d in RStudio). Problem: I am use to copy my example at the end of the function documentation, somtimes I forget to add the @examples tag. Correction: add @examples before the example.  Namespace problems Examples\nIn loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : there is no package called ‘ggplot’  Resolution:\nDelete the namespace file and generate documentation.\n"
},
{
	"uri": "/r_content/roc_01/roc_01.html",
	"title": "ROC Curves",
	"tags": ["ROC", "graph", "ggplot2"],
	"description": "",
	"content": "2021-01-11, FCA Collin (update 2021-01-12)\nPresentation The Receiver Operating Characteristic (ROC) is a general representation of a binary classifier; it accounts for:\n the sensitivity (the proportion of real positive case detected), the false positive rate (1 - sensitivity), the general performance via the area under the ROC curve (AUC).  The classifier for the example identifies tumour tissues (yes/no) in the case of lung cancer (LC) or eventually identifies the Squamous Cell Carcinoma (SCC) histological subtype. The dataset used for the graphic requires at least columns for the sensitivity, the false-positive rate and a decision rule represented by a threshold proportion, in that case varying from 0 to 1. Additionally, information about the classifier itself can include the model identification (LC, SCC), as well as the AUC (+ confidence interval estimation) as a overall evaluation of the models.\nData Lets dtaplot being as example dataset such as:\n   Threshold Sensitivity Specificity FalseAlarm ntree auc.ci auc Diag     Inf 0.0000000 1 0 10000 0.925-0.984 0.954 2) SCC   Inf 0.0000000 1 0 10000 0.938-0.989 0.964 1) LC   0.96445 0.0097087 1 0 10000 0.925-0.984 0.954 2) SCC   0.95860 0.0194175 1 0 10000 0.925-0.984 0.954 2) SCC   0.95375 0.0291262 1 0 10000 0.925-0.984 0.954 2) SCC   0.95285 0.0388350 1 0 10000 0.925-0.984 0.954 2) SCC    Some decision rules (threshold) were of interest:\n Min. error is the threshold for which the classifier overall error was at its minimum. Sens. 90%: has its better not to miss true positive patients, the threshold may be determined so as to catch 90% of true positive patient (sensibility), eventually at a cost in terms of overall error as it then automatically increase the false-alarm rate.  Lets threshold being the supplementary data characterising this two decision rules:\n`Threshold, the decision rules.    Threshold Sensitivity Specificity FalseAlarm ntree auc.ci auc Diag target Rational    0.48965 0.9368421 0.9375000 0.0625000 10000 0.938-0.989 0.964 1) LC 0.0103500 Min. error  0.49350 0.8640777 0.9813953 0.0186047 10000 0.925-0.984 0.954 2) SCC 0.0065000 Min. error  0.69835 0.9000000 0.9687500 0.0312500 10000 0.938-0.989 0.964 1) LC 0.0000000 Sens. 90%  0.35290 0.9029126 0.9441860 0.0558140 10000 0.925-0.984 0.954 2) SCC 0.0029126 Sens. 90%    Graphic The example is based on the package ggplot2, plus the optional ggthemr which provides graphical themes, for instance the themeflat.\nlibrary(ggplot2) if(require(ggthemr)) ggthemr::ggthemr(\u0026#34;flat\u0026#34;) Basic The minimal ROC representation is simply a line plot representing the sensitivity as a function of the false alarm rate, for one or the other model.\nggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, color = Diag ) ) + geom_line( lwd = 1 ) + facet_grid( . ~ Diag ) Aesthetic improvement Aesthetic can help improving the reading:\n the area under the curve is of interest, therefore it can be filled. the bisector delimits a model performing as good as a decision made flipping a coin (the reference model). sensibility and false-alarm rate are define from 0 to 1, the length of this two axis should equal.  { ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + theme( asp = 1 ) } Other data for more annotations The use of the model for diagnostic demands to define a threshold, various rational can be used, in the example two thresholds were defined: the minimal error, the 90% detection of positive case. Points can identify this threshold and performance on the ROC curve.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + theme( asp = 1 ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) } The plot can be further personalised manipulating the theme locally to address for instance the positioning of the legend and other settings.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) + theme( asp = 1, legend.position = \u0026#34;bottom\u0026#34;, legend.text = element_text(size = 8), legend.title = element_text(size = 8), legend.background = element_rect(fill = \u0026#34;transparent\u0026#34;), plot.background = element_rect(fill = alpha(\u0026#34;white\u0026#34;, .5), colour = \u0026#39;white\u0026#39;) ) } Final Finally, as a last piece of annotation, the AUC given with its confidence interval may help for further comparison.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) + theme( asp = 1, legend.position = \u0026#34;bottom\u0026#34;, legend.text = element_text(size = 8), legend.title = element_text(size = 8), legend.background = element_rect(fill = \u0026#34;transparent\u0026#34;), plot.background = element_rect(fill = alpha(\u0026#34;white\u0026#34;, .5), colour = \u0026#39;white\u0026#39;) ) + geom_label( data = aggregate(auc.ci ~ Diag + ntree, data = dtaplot, unique), mapping = aes(label = auc.ci, ymax = NULL, fill = NULL, color = NULL , x = .5, y = .5 ) ) } sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggthemr_1.1.0 ggplot2_3.3.3 ## ## loaded via a namespace (and not attached): ## [1] pillar_1.5.1 compiler_4.0.4 highr_0.8 tools_4.0.4 ## [5] digest_0.6.27 evaluate_0.14 lifecycle_1.0.0 tibble_3.1.0 ## [9] gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.10 DBI_1.1.1 ## [13] yaml_2.2.1 xfun_0.22 withr_2.4.1 stringr_1.4.0 ## [17] dplyr_1.0.5 knitr_1.31 generics_0.1.0 vctrs_0.3.7 ## [21] grid_4.0.4 tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 ## [25] fansi_0.4.2 rmarkdown_2.6 farver_2.1.0 purrr_0.3.4 ## [29] magrittr_2.0.1 scales_1.1.1 ellipsis_0.3.1 htmltools_0.5.1.1 ## [33] assertthat_0.2.1 colorspace_2.0-0 labeling_0.4.2 utf8_1.2.1 ## [37] stringi_1.5.3 munsell_0.5.0 crayon_1.4.1 "
},
{
	"uri": "/r_content/btc.html",
	"title": "Beat The Code",
	"tags": [],
	"description": "",
	"content": "In content/r_content/, R outputs are organised in folder, a folder corresponds to an item in the navigation menu.\n"
},
{
	"uri": "/r_content.html",
	"title": "R Content",
	"tags": [],
	"description": "",
	"content": "In content/r_content/, R outputs are organised in folder, a folder corresponds to an item in the navigation menu.\n"
},
{
	"uri": "/standard.html",
	"title": "Standard",
	"tags": [],
	"description": "",
	"content": "Standard and information.\n"
},
{
	"uri": "/faq.html",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": "I regularly encounter some errors, it may be time to keep track of them and propose standard resolutions.\n"
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/debug.html",
	"title": "Debug",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/error.html",
	"title": "Error",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/ggplot2.html",
	"title": "Ggplot2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/graph.html",
	"title": "Graph",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/guide.html",
	"title": "Guide",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/",
	"title": "Guide",
	"tags": ["hugo", "guide"],
	"description": "",
	"content": " Welcome 2021-03-10, FCA Collin\nThis guide contains information for stakeholders about methods used in when I develop programs. This is still a fairly new initiative and is likely to strongly evolve in the coming months.\nUnder The Hood This is an example of static web page generated with Hugo. No big knowledge of html, Hugo comes with ready-to-use features, further augmented by themes . For instance, the learn theme used for these pages has nice features for project documentation, included but not restricted to:\n keyword search box in the top-left corner. content folder structure corresponding to the left expandable navigation menu. the code is highlighted.  Try the search box in the top-left corner and look for ggplot2.\n Different themes serve different purpose, I have found the Creative portfolio especially useful to present my \u0026hellip; portfolio!\nGitHub repository, check directory hugo.\nThe user simply edits the content folder with markdown files, adds figures, docs, or other elements in the static folder and run the commandhugoto render the webpage in thepublic` folder. Nicely, with the following comment the website is dynamically rendered at http://localhost:1313/ and modifications of the source are automatically rendered.\nhugo server  Credits  Hugo-theme-learn is a theme for Hugo, a fast and modern static website engine written in Go.  "
},
{
	"uri": "/tags/hugo.html",
	"title": "Hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/lifecycle.html",
	"title": "Lifecycle",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/roc.html",
	"title": "Roc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/warning.html",
	"title": "Warning",
	"tags": [],
	"description": "",
	"content": ""
}]